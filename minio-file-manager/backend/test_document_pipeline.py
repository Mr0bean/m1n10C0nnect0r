#!/usr/bin/env python3
"""
æµ‹è¯•æ–‡æ¡£å¤„ç†ç®¡é“åŠŸèƒ½
æµ‹è¯•MD/HTMLæ–‡ä»¶ä¸Šä¼ åˆ°MinIOå¹¶åŒæ—¶ç´¢å¼•åˆ°Elasticsearch
"""

import asyncio
import aiohttp
import json
from pathlib import Path
import tempfile

API_BASE_URL = "http://localhost:9011/api/v1"


async def create_test_files():
    """åˆ›å»ºæµ‹è¯•æ–‡ä»¶"""
    test_files = []
    
    # åˆ›å»ºæµ‹è¯•Markdownæ–‡ä»¶
    md_content = """# é¡¹ç›®æ–‡æ¡£

## æ¦‚è¿°
è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é¡¹ç›®çš„æŠ€æœ¯æ–‡æ¡£ã€‚

## åŠŸèƒ½ç‰¹æ€§
- æ”¯æŒMarkdownæ ¼å¼
- è‡ªåŠ¨ç´¢å¼•åˆ°Elasticsearch
- æ”¯æŒæ¨¡ç³Šæœç´¢
- å…¬å¼€URLè®¿é—®

## ä»£ç ç¤ºä¾‹
```python
def hello_world():
    print("Hello, World!")
```

## é“¾æ¥
- [é¡¹ç›®ä¸»é¡µ](https://example.com)
- [APIæ–‡æ¡£](https://api.example.com)

## æ€»ç»“
è¿™ä¸ªæ–‡æ¡£å±•ç¤ºäº†pipelineçš„åŠŸèƒ½ã€‚
"""
    
    md_file = tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False)
    md_file.write(md_content)
    md_file.close()
    test_files.append(('markdown', md_file.name, 'test_project.md'))
    
    # åˆ›å»ºæµ‹è¯•HTMLæ–‡ä»¶
    html_content = """<!DOCTYPE html>
<html>
<head>
    <title>æµ‹è¯•HTMLæ–‡æ¡£</title>
    <meta name="description" content="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•HTMLæ–‡æ¡£ï¼Œç”¨äºæ¼”ç¤ºpipelineåŠŸèƒ½">
    <meta name="keywords" content="æµ‹è¯•,HTML,pipeline,elasticsearch">
    <meta name="author" content="æµ‹è¯•ä½œè€…">
</head>
<body>
    <h1>HTMLæ–‡æ¡£æµ‹è¯•</h1>
    <p>è¿™æ˜¯ä¸€ä¸ªHTMLæ ¼å¼çš„æ–‡æ¡£ï¼Œä¼šè¢«è‡ªåŠ¨å¤„ç†å¹¶ç´¢å¼•ã€‚</p>
    <h2>åŠŸèƒ½åˆ—è¡¨</h2>
    <ul>
        <li>è‡ªåŠ¨æå–æ–‡æœ¬å†…å®¹</li>
        <li>è§£æmetaæ ‡ç­¾</li>
        <li>ç”Ÿæˆæœç´¢ç´¢å¼•</li>
    </ul>
    <p>è®¿é—®é“¾æ¥ï¼š<a href="https://example.org">ç¤ºä¾‹ç½‘ç«™</a></p>
</body>
</html>"""
    
    html_file = tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False)
    html_file.write(html_content)
    html_file.close()
    test_files.append(('html', html_file.name, 'test_document.html'))
    
    # åˆ›å»ºæ™®é€šæ–‡æœ¬æ–‡ä»¶ï¼ˆä¸ä¼šè¢«pipelineå¤„ç†ï¼‰
    txt_content = """è¿™æ˜¯ä¸€ä¸ªæ™®é€šçš„æ–‡æœ¬æ–‡ä»¶ã€‚
å®ƒä¸ä¼šè¢«pipelineå¤„ç†ï¼Œåªä¼šä¸Šä¼ åˆ°MinIOã€‚"""
    
    txt_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False)
    txt_file.write(txt_content)
    txt_file.close()
    test_files.append(('text', txt_file.name, 'normal_text.txt'))
    
    return test_files


async def ensure_bucket_exists(session, bucket_name):
    """ç¡®ä¿å­˜å‚¨æ¡¶å­˜åœ¨"""
    # æ£€æŸ¥å­˜å‚¨æ¡¶æ˜¯å¦å­˜åœ¨
    async with session.get(f"{API_BASE_URL}/buckets") as resp:
        if resp.status == 200:
            buckets = await resp.json()
            if not any(b['name'] == bucket_name for b in buckets):
                # åˆ›å»ºå­˜å‚¨æ¡¶
                async with session.post(
                    f"{API_BASE_URL}/buckets",
                    json={"bucket_name": bucket_name}
                ) as create_resp:
                    if create_resp.status in [200, 201]:
                        print(f"âœ… åˆ›å»ºå­˜å‚¨æ¡¶: {bucket_name}")
                    else:
                        print(f"âŒ åˆ›å»ºå­˜å‚¨æ¡¶å¤±è´¥: {await create_resp.text()}")
            else:
                print(f"âœ… å­˜å‚¨æ¡¶å·²å­˜åœ¨: {bucket_name}")


async def upload_file(session, bucket_name, file_path, object_name):
    """ä¸Šä¼ æ–‡ä»¶åˆ°MinIO"""
    with open(file_path, 'rb') as f:
        data = aiohttp.FormData()
        data.add_field('file', f, filename=object_name)
        
        async with session.post(
            f"{API_BASE_URL}/objects/{bucket_name}/upload",
            data=data,
            params={'object_name': object_name, 'use_pipeline': 'true'}
        ) as resp:
            if resp.status in [200, 201]:
                result = await resp.json()
                return result
            else:
                print(f"âŒ ä¸Šä¼ å¤±è´¥: {await resp.text()}")
                return None


async def search_documents(session, query, fuzzy=True):
    """æœç´¢æ–‡æ¡£"""
    params = {
        'query': query,
        'fuzzy': str(fuzzy).lower(),
        'size': 10
    }
    
    async with session.get(
        f"{API_BASE_URL}/documents/search",
        params=params
    ) as resp:
        if resp.status == 200:
            return await resp.json()
        else:
            print(f"âŒ æœç´¢å¤±è´¥: {await resp.text()}")
            return None


async def get_similar_documents(session, document_id):
    """è·å–ç›¸ä¼¼æ–‡æ¡£"""
    async with session.get(
        f"{API_BASE_URL}/documents/similar/{document_id}",
        params={'size': 5}
    ) as resp:
        if resp.status == 200:
            return await resp.json()
        elif resp.status == 404:
            print(f"âŒ æ–‡æ¡£æœªæ‰¾åˆ°: {document_id}")
            return None
        else:
            print(f"âŒ è·å–ç›¸ä¼¼æ–‡æ¡£å¤±è´¥: {await resp.text()}")
            return None


async def get_document_stats(session):
    """è·å–æ–‡æ¡£ç»Ÿè®¡"""
    async with session.get(f"{API_BASE_URL}/documents/stats") as resp:
        if resp.status == 200:
            return await resp.json()
        else:
            print(f"âŒ è·å–ç»Ÿè®¡å¤±è´¥: {await resp.text()}")
            return None


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("=" * 60)
    print("æµ‹è¯•æ–‡æ¡£å¤„ç†ç®¡é“ï¼ˆPipelineï¼‰")
    print("=" * 60)
    
    bucket_name = "test-documents"
    
    async with aiohttp.ClientSession() as session:
        # 1. ç¡®ä¿å­˜å‚¨æ¡¶å­˜åœ¨
        print("\n1. å‡†å¤‡å­˜å‚¨æ¡¶")
        print("-" * 40)
        await ensure_bucket_exists(session, bucket_name)
        
        # 2. åˆ›å»ºå¹¶ä¸Šä¼ æµ‹è¯•æ–‡ä»¶
        print("\n2. ä¸Šä¼ æµ‹è¯•æ–‡ä»¶")
        print("-" * 40)
        test_files = await create_test_files()
        uploaded_docs = []
        
        for file_type, file_path, object_name in test_files:
            print(f"\nä¸Šä¼  {file_type} æ–‡ä»¶: {object_name}")
            result = await upload_file(session, bucket_name, file_path, object_name)
            if result:
                print(f"  âœ… ä¸Šä¼ æˆåŠŸ")
                print(f"  ğŸ“¦ å­˜å‚¨æ¡¶: {result.get('bucket')}")
                print(f"  ğŸ“„ å¯¹è±¡å: {result.get('object_name')}")
                if result.get('es_indexed'):
                    print(f"  ğŸ” å·²ç´¢å¼•åˆ°ES: {result.get('es_document_id')}")
                    uploaded_docs.append(result.get('es_document_id'))
                if result.get('public_url'):
                    print(f"  ğŸŒ å…¬å¼€URL: {result.get('public_url')}")
                print(f"  ğŸ’¬ æ¶ˆæ¯: {result.get('message', 'ä¸Šä¼ æˆåŠŸ')}")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            Path(file_path).unlink()
        
        # ç­‰å¾…ESç´¢å¼•
        print("\nâ³ ç­‰å¾…Elasticsearchç´¢å¼•...")
        await asyncio.sleep(2)
        
        # 3. æµ‹è¯•æœç´¢åŠŸèƒ½
        print("\n3. æµ‹è¯•æ–‡æ¡£æœç´¢")
        print("-" * 40)
        
        # ç²¾ç¡®æœç´¢
        print("\nğŸ“ ç²¾ç¡®æœç´¢: 'Elasticsearch'")
        search_result = await search_documents(session, "Elasticsearch", fuzzy=False)
        if search_result:
            print(f"  æ‰¾åˆ° {search_result['total']} ä¸ªæ–‡æ¡£")
            for doc in search_result['documents'][:3]:
                print(f"  - {doc.get('title', doc.get('object_name'))}")
                print(f"    è¯„åˆ†: {doc.get('_score', 0):.2f}")
                if '_highlight' in doc:
                    print(f"    é«˜äº®: {doc['_highlight']}")
        
        # æ¨¡ç³Šæœç´¢
        print("\nğŸ” æ¨¡ç³Šæœç´¢: 'elasicsearch' (æ•…æ„æ‹¼é”™)")
        fuzzy_result = await search_documents(session, "elasicsearch", fuzzy=True)
        if fuzzy_result:
            print(f"  æ‰¾åˆ° {fuzzy_result['total']} ä¸ªæ–‡æ¡£ï¼ˆé€šè¿‡æ¨¡ç³ŠåŒ¹é…ï¼‰")
            for doc in fuzzy_result['documents'][:3]:
                print(f"  - {doc.get('title', doc.get('object_name'))}")
        
        # 4. æµ‹è¯•ç›¸ä¼¼æ–‡æ¡£æ¨è
        if uploaded_docs:
            print("\n4. æµ‹è¯•ç›¸ä¼¼æ–‡æ¡£æ¨è")
            print("-" * 40)
            doc_id = uploaded_docs[0]
            print(f"\nè·å–ä¸æ–‡æ¡£ {doc_id[:8]}... ç›¸ä¼¼çš„æ–‡æ¡£")
            similar = await get_similar_documents(session, doc_id)
            if similar:
                print(f"  æ‰¾åˆ° {len(similar['similar_documents'])} ä¸ªç›¸ä¼¼æ–‡æ¡£")
                for doc in similar['similar_documents']:
                    print(f"  - {doc.get('title', doc.get('object_name'))}")
                    print(f"    ç›¸ä¼¼åº¦è¯„åˆ†: {doc.get('_score', 0):.2f}")
        
        # 5. è·å–ç»Ÿè®¡ä¿¡æ¯
        print("\n5. æ–‡æ¡£ç´¢å¼•ç»Ÿè®¡")
        print("-" * 40)
        stats = await get_document_stats(session)
        if stats:
            print(f"  ğŸ“Š æ€»æ–‡æ¡£æ•°: {stats['total_documents']}")
            print(f"  ğŸ“ æŒ‰ç±»å‹ç»Ÿè®¡:")
            for type_stat in stats['by_document_type']:
                print(f"    - {type_stat['type']}: {type_stat['count']} ä¸ª")
            print(f"  ğŸ—‚ï¸ æŒ‰å­˜å‚¨æ¡¶ç»Ÿè®¡:")
            for bucket_stat in stats['by_bucket']:
                print(f"    - {bucket_stat['bucket']}: {bucket_stat['count']} ä¸ª")
            if stats.get('average_word_count'):
                print(f"  ğŸ“ å¹³å‡å­—æ•°: {stats['average_word_count']}")
    
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())